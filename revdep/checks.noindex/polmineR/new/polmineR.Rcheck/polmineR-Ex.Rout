
R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "polmineR"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('polmineR')
polmineR v0.7.10
session registry:  /private/var/folders/0w/prb4hnss2gn1p7y34qb2stw00000gp/T/RtmpZOBcNJ/polmineR_registry
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("Corpus-class")
> ### * Corpus-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Corpus
> ### Title: Corpus class.
> ### Aliases: Corpus
> ### Keywords: datasets
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> REUTERS <- Corpus$new("REUTERS")
> infofile <- REUTERS$getInfo()
> if (interactive()) REUTERS$showInfo()
> 
> # use Corpus class to manage counts
> REUTERS <- Corpus$new("REUTERS", p_attribute = "word")
> REUTERS$stat
             word word_id count
   1:          03     728     1
   2:           1     709     3
   3:         1.1     964     1
   4:        1.11    1189     1
   5:        1.15    1185     1
  ---                          
1188:   yesterday     693     4
1189: yesterday's     683     1
1190:         you     157     1
1191:        zero     612     2
1192:        zone     915     2
> 
> # use Corpus class for creating partitions
> REUTERS <- Corpus$new("REUTERS", s_attributes = c("id", "places"))
... decoding s-attribute:  id
... decoding s-attribute:  places
> usa <- partition(REUTERS, places = "usa")
... encoding of the corpus is: latin1
... initialize partition  
... get cpos and strucs
> sa <- partition(REUTERS, places = "saudi-arabia", regex = TRUE)
... encoding of the corpus is: latin1
... initialize partition  
... get cpos and strucs
> 
> reut <- REUTERS$as.partition()
> 
> 
> 
> cleanEx()
> nameEx("as.DocumentTermMatrix")
> ### * as.DocumentTermMatrix
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: as.TermDocumentMatrix
> ### Title: Generate TermDocumentMatrix / DocumentTermMatrix.
> ### Aliases: as.TermDocumentMatrix as.DocumentTermMatrix
> ###   as.DocumentTermMatrix as.TermDocumentMatrix,character-method
> ###   as.DocumentTermMatrix,character-method
> ###   as.TermDocumentMatrix,bundle-method
> ###   as.DocumentTermMatrix,bundle-method
> ###   as.TermDocumentMatrix,partition_bundle-method
> ###   as.DocumentTermMatrix,partition_bundle-method
> ###   as.DocumentTermMatrix,context-method
> ###   as.TermDocumentMatrix,context-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
>  
> # do-it-yourself 
> p <- partition("GERMAPARLMINI", date = ".*", regex = TRUE)
... get encoding: latin1
... get cpos and strucs
> pB <- partition_bundle(p, s_attribute = "date")
... getting values for s-attribute  date
... number of partitions to be generated:  5
> pB <- enrich(pB, p_attribute="word")
> tdm <- as.TermDocumentMatrix(pB, col = "count")
... using the p_attribute-slot of the first object in the bundle as p_attribute: word
... generating (temporary) key column
... generating cumulated data.table
... getting unique keys
... generating integer keys
... cleaning up temporary key columns
>    
>  # leave the counting to the as.TermDocumentMatrix-method
> pB2 <- partition_bundle(p, s_attribute = "date")
... getting values for s-attribute  date
... number of partitions to be generated:  5
> tdm <- as.TermDocumentMatrix(pB2, p_attribute = "word", verbose = TRUE)
... generating corpus positions
... getting ids
... performing count
... generating keys
... generating simple triplet matrix
>    
> # diretissima
> tdm <- as.TermDocumentMatrix("GERMAPARLMINI", p_attribute = "word", s_attribute = "date")
... generate data.table with token and struc ids
... generate unique document ids
... counting token per doc
... generate simple_triplet_matrix
... add row and column labels
> 
> 
> 
> cleanEx()
> nameEx("as.VCorpus")
> ### * as.VCorpus
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: as.VCorpus
> ### Title: Coerce partition_bundle to VCorpus.
> ### Aliases: as.VCorpus as.VCorpus,partition_bundle-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> P <- partition("GERMAPARLMINI", date = "2009-11-10")
... get encoding: latin1
... get cpos and strucs
> PB <- partition_bundle(P, s_attribute = "speaker")
... getting values for s-attribute  speaker
... number of partitions to be generated:  37
> VC <- as.VCorpus(PB)
Using only the s-attributes that have the same length as the s-attribute in the slot s_attribute_strucs of the first partition
> 
> 
> 
> cleanEx()
> nameEx("as.markdown")
> ### * as.markdown
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: as.markdown
> ### Title: Get markdown-formatted full text of a partition.
> ### Aliases: as.markdown as.markdown,partition-method
> ###   as.markdown,plpr_partition-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> P <- partition("REUTERS", places = "argentina")
... get encoding: latin1
... get cpos and strucs
> as.markdown(P)
[1] "## Corpus: REUTERS\n\n###  \n\n <span id=\"3997\" token=\"Argentine\" class=\"fulltext\">Argentine</span> <span id=\"3998\" token=\"crude\" class=\"fulltext\">crude</span> <span id=\"3999\" token=\"oil\" class=\"fulltext\">oil</span> <span id=\"4000\" token=\"production\" class=\"fulltext\">production</span> <span id=\"4001\" token=\"was\" class=\"fulltext\">was</span> <span id=\"4002\" token=\"down\" class=\"fulltext\">down</span> <span id=\"4003\" token=\"10.8\" class=\"fulltext\">10.8</span> <span id=\"4004\" token=\"pct\" class=\"fulltext\">pct</span> <span id=\"4005\" token=\"in\" class=\"fulltext\">in</span> <span id=\"4006\" token=\"January\" class=\"fulltext\">January</span> <span id=\"4007\" token=\"1987\" class=\"fulltext\">1987</span> <span id=\"4008\" token=\"to\" class=\"fulltext\">to</span> <span id=\"4009\" token=\"12.32\" class=\"fulltext\">12.32</span> <span id=\"4010\" token=\"mln\" class=\"fulltext\">mln</span> <span id=\"4011\" token=\"barrels\" class=\"fulltext\">barrels</span> <span id=\"4012\" token=\"from\" class=\"fulltext\">from</span> <span id=\"4013\" token=\"13.81\" class=\"fulltext\">13.81</span> <span id=\"4014\" token=\"mln\" class=\"fulltext\">mln</span> <span id=\"4015\" token=\"barrels\" class=\"fulltext\">barrels</span> <span id=\"4016\" token=\"in\" class=\"fulltext\">in</span> <span id=\"4017\" token=\"January\" class=\"fulltext\">January</span> <span id=\"4018\" token=\"1986\" class=\"fulltext\">1986</span> <span id=\"4019\" token=\"Yacimientos\" class=\"fulltext\">Yacimientos</span> <span id=\"4020\" token=\"Petroliferos\" class=\"fulltext\">Petroliferos</span> <span id=\"4021\" token=\"Fiscales\" class=\"fulltext\">Fiscales</span> <span id=\"4022\" token=\"said\" class=\"fulltext\">said</span> <span id=\"4023\" token=\"January\" class=\"fulltext\">January</span> <span id=\"4024\" token=\"1987\" class=\"fulltext\">1987</span> <span id=\"4025\" token=\"natural\" class=\"fulltext\">natural</span> <span id=\"4026\" token=\"gas\" class=\"fulltext\">gas</span> <span id=\"4027\" token=\"output\" class=\"fulltext\">output</span> <span id=\"4028\" token=\"totalled\" class=\"fulltext\">totalled</span> <span id=\"4029\" token=\"1.15\" class=\"fulltext\">1.15</span> <span id=\"4030\" token=\"billion\" class=\"fulltext\">billion</span> <span id=\"4031\" token=\"cubic\" class=\"fulltext\">cubic</span> <span id=\"4032\" token=\"metrers\" class=\"fulltext\">metrers</span> <span id=\"4033\" token=\"3.6\" class=\"fulltext\">3.6</span> <span id=\"4034\" token=\"pct\" class=\"fulltext\">pct</span> <span id=\"4035\" token=\"higher\" class=\"fulltext\">higher</span> <span id=\"4036\" token=\"than\" class=\"fulltext\">than</span> <span id=\"4037\" token=\"1.11\" class=\"fulltext\">1.11</span> <span id=\"4038\" token=\"billion\" class=\"fulltext\">billion</span> <span id=\"4039\" token=\"cubic\" class=\"fulltext\">cubic</span> <span id=\"4040\" token=\"metres\" class=\"fulltext\">metres</span> <span id=\"4041\" token=\"produced\" class=\"fulltext\">produced</span> <span id=\"4042\" token=\"in\" class=\"fulltext\">in</span> <span id=\"4043\" token=\"January\" class=\"fulltext\">January</span> <span id=\"4044\" token=\"1986\" class=\"fulltext\">1986</span> <span id=\"4045\" token=\"Yacimientos\" class=\"fulltext\">Yacimientos</span> <span id=\"4046\" token=\"Petroliferos\" class=\"fulltext\">Petroliferos</span> <span id=\"4047\" token=\"Fiscales\" class=\"fulltext\">Fiscales</span> <span id=\"4048\" token=\"added\" class=\"fulltext\">added</span> <span id=\"4049\" token=\"Reuter\" class=\"fulltext\">Reuter</span> \n"
> as.markdown(P, meta = c("id", "places"))
[1] "## Corpus: REUTERS\n\n###  id: 708 // places: argentina\n\n <span id=\"3997\" token=\"Argentine\" class=\"fulltext\">Argentine</span> <span id=\"3998\" token=\"crude\" class=\"fulltext\">crude</span> <span id=\"3999\" token=\"oil\" class=\"fulltext\">oil</span> <span id=\"4000\" token=\"production\" class=\"fulltext\">production</span> <span id=\"4001\" token=\"was\" class=\"fulltext\">was</span> <span id=\"4002\" token=\"down\" class=\"fulltext\">down</span> <span id=\"4003\" token=\"10.8\" class=\"fulltext\">10.8</span> <span id=\"4004\" token=\"pct\" class=\"fulltext\">pct</span> <span id=\"4005\" token=\"in\" class=\"fulltext\">in</span> <span id=\"4006\" token=\"January\" class=\"fulltext\">January</span> <span id=\"4007\" token=\"1987\" class=\"fulltext\">1987</span> <span id=\"4008\" token=\"to\" class=\"fulltext\">to</span> <span id=\"4009\" token=\"12.32\" class=\"fulltext\">12.32</span> <span id=\"4010\" token=\"mln\" class=\"fulltext\">mln</span> <span id=\"4011\" token=\"barrels\" class=\"fulltext\">barrels</span> <span id=\"4012\" token=\"from\" class=\"fulltext\">from</span> <span id=\"4013\" token=\"13.81\" class=\"fulltext\">13.81</span> <span id=\"4014\" token=\"mln\" class=\"fulltext\">mln</span> <span id=\"4015\" token=\"barrels\" class=\"fulltext\">barrels</span> <span id=\"4016\" token=\"in\" class=\"fulltext\">in</span> <span id=\"4017\" token=\"January\" class=\"fulltext\">January</span> <span id=\"4018\" token=\"1986\" class=\"fulltext\">1986</span> <span id=\"4019\" token=\"Yacimientos\" class=\"fulltext\">Yacimientos</span> <span id=\"4020\" token=\"Petroliferos\" class=\"fulltext\">Petroliferos</span> <span id=\"4021\" token=\"Fiscales\" class=\"fulltext\">Fiscales</span> <span id=\"4022\" token=\"said\" class=\"fulltext\">said</span> <span id=\"4023\" token=\"January\" class=\"fulltext\">January</span> <span id=\"4024\" token=\"1987\" class=\"fulltext\">1987</span> <span id=\"4025\" token=\"natural\" class=\"fulltext\">natural</span> <span id=\"4026\" token=\"gas\" class=\"fulltext\">gas</span> <span id=\"4027\" token=\"output\" class=\"fulltext\">output</span> <span id=\"4028\" token=\"totalled\" class=\"fulltext\">totalled</span> <span id=\"4029\" token=\"1.15\" class=\"fulltext\">1.15</span> <span id=\"4030\" token=\"billion\" class=\"fulltext\">billion</span> <span id=\"4031\" token=\"cubic\" class=\"fulltext\">cubic</span> <span id=\"4032\" token=\"metrers\" class=\"fulltext\">metrers</span> <span id=\"4033\" token=\"3.6\" class=\"fulltext\">3.6</span> <span id=\"4034\" token=\"pct\" class=\"fulltext\">pct</span> <span id=\"4035\" token=\"higher\" class=\"fulltext\">higher</span> <span id=\"4036\" token=\"than\" class=\"fulltext\">than</span> <span id=\"4037\" token=\"1.11\" class=\"fulltext\">1.11</span> <span id=\"4038\" token=\"billion\" class=\"fulltext\">billion</span> <span id=\"4039\" token=\"cubic\" class=\"fulltext\">cubic</span> <span id=\"4040\" token=\"metres\" class=\"fulltext\">metres</span> <span id=\"4041\" token=\"produced\" class=\"fulltext\">produced</span> <span id=\"4042\" token=\"in\" class=\"fulltext\">in</span> <span id=\"4043\" token=\"January\" class=\"fulltext\">January</span> <span id=\"4044\" token=\"1986\" class=\"fulltext\">1986</span> <span id=\"4045\" token=\"Yacimientos\" class=\"fulltext\">Yacimientos</span> <span id=\"4046\" token=\"Petroliferos\" class=\"fulltext\">Petroliferos</span> <span id=\"4047\" token=\"Fiscales\" class=\"fulltext\">Fiscales</span> <span id=\"4048\" token=\"added\" class=\"fulltext\">added</span> <span id=\"4049\" token=\"Reuter\" class=\"fulltext\">Reuter</span> \n"
> if (interactive()) read(P, meta = c("id", "places"))
> 
> 
> 
> cleanEx()
> nameEx("as.speeches")
> ### * as.speeches
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: as.speeches
> ### Title: Split corpus or partition into speeches.
> ### Aliases: as.speeches
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> speeches <- as.speeches(
+   "GERMAPARLMINI",
+   s_attribute_date = "date", s_attribute_name = "speaker"
+ )
... generating partitions by date
... getting matrix with regions for s-attribute:  date
... generating the partitions
... generating speeches
... generating names
... reordering partitions
... coercing partitions to plpr_partitions
> speeches_count <- count(speeches, p_attribute = "word")
> tdm <- as.TermDocumentMatrix(speeches_count, col = "count")
... using the p_attribute-slot of the first object in the bundle as p_attribute: word
... generating (temporary) key column
... generating cumulated data.table
... getting unique keys
... generating integer keys
... cleaning up temporary key columns
> 
> bt <- partition("GERMAPARLMINI", date = "2009-10-27")
... get encoding: latin1
... get cpos and strucs
> speeches <- as.speeches(bt, s_attribute_name = "speaker")
... generating partitions by date
... generating speeches
... generating names
... reordering partitions
... coercing partitions to plpr_partitions
> summary(speeches)
                                name size
1     Heinz Riesenhuber_2009-10-27_1 4766
2         Volker Kauder_2009-10-27_1   38
3       Norbert Lammert_2009-10-27_1 4441
4     Gerda Hasselfeldt_2009-10-27_1   23
5      Wolfgang Thierse_2009-10-27_1   14
6    Hermann Otto Solms_2009-10-27_1   17
7             Petra Pau_2009-10-27_1   25
8 Katrin Göring-Eckardt_2009-10-27_1   17
> 
> 
> 
> cleanEx()
> nameEx("blapply")
> ### * blapply
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: blapply
> ### Title: apply a function over a list or bundle
> ### Aliases: blapply blapply,list-method blapply,vector-method
> ###   blapply,bundle-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> bt <- partition("GERMAPARLMINI", date = ".*", regex=TRUE)
... get encoding: latin1
... get cpos and strucs
> speeches <- as.speeches(bt, s_attribute_date = "date", s_attribute_name = "speaker")
... generating partitions by date
... getting values for s-attribute  date
... number of partitions to be generated:  5
... generating speeches
... generating names
... reordering partitions
... coercing partitions to plpr_partitions
> foo <- blapply(speeches, function(x, ...) slot(x, "cpos"))
> 
> 
> 
> cleanEx()
> nameEx("bundle")
> ### * bundle
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bundle-class
> ### Title: Bundle Class
> ### Aliases: bundle-class bundle name<-,bundle,character-method
> ###   length,bundle-method names,bundle-method names<-,bundle,vector-method
> ###   unique,bundle-method +,bundle,bundle-method +,bundle,textstat-method
> ###   [[,bundle-method sample,bundle-method as.bundle,list-method
> ###   as.bundle,textstat-method as.data.table,bundle-method
> ###   as.matrix,bundle-method subset,bundle-method as.list,bundle-method
> 
> ### ** Examples
> 
> parties <- s_attributes("GERMAPARLMINI", "party")
> parties <- parties[-which(parties == "NA")]
> party_bundle <- partition_bundle("GERMAPARLMINI", s_attribute = "party")
... getting matrix with regions for s-attribute:  party
... generating the partitions
> length(party_bundle)
[1] 6
> names(party_bundle)
[1] "B90_DIE_GRUENEN" "CDU_CSU"         "DIE_LINKE"       "FDP"            
[5] "NA"              "SPD"            
> party_bundle <- enrich(party_bundle, p_attribute = "word")
> summary(party_bundle)
             name  size p_attribute unique
1 B90_DIE_GRUENEN 23052        word   4186
2         CDU_CSU 66490        word   8486
3       DIE_LINKE 22542        word   4531
4             FDP 31505        word   4930
5              NA 31310        word   5032
6             SPD 47302        word   6692
> parties_big <- party_bundle[[c("CDU_CSU", "SPD")]]
> summary(parties_big)
     name  size p_attribute unique
1 CDU_CSU 66490        word   8486
2     SPD 47302        word   6692
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> Ps <- partition_bundle(
+   "REUTERS", s_attribute = "id",
+   values = s_attributes("REUTERS", "id")
+ )
... getting matrix with regions for s-attribute:  id
... generating the partitions
> Cs <- cooccurrences(Ps, query = "oil", cqp = FALSE, verbose = FALSE, progress = TRUE)
Warning in .local(.Object, ...) :
  No hits for query oil (returning NULL)
> dt <- as.data.table(Cs, col = "ll")
> m <- as.matrix(Cs, col = "ll")
> 
> 
> 
> cleanEx()
> nameEx("context-method")
> ### * context-method
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: context
> ### Title: Analyze context of a node word.
> ### Aliases: context context as.matrix,context_bundle-method
> ###   context,partition-method context,character-method
> ###   context,partition_bundle-method context,cooccurrences-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> p <- partition("GERMAPARLMINI", interjection = "speech")
... get encoding: latin1
... get cpos and strucs
> y <- context(p, query = "Integration", p_attribute = "word")
... getting corpus positions
... number of hits: 23
... checking that all p-attributes are available
... getting token id for p-attribute: word
... generating contexts
... counting tokens
> y <- context(p, query = "Integration", p_attribute = "word", positivelist = "Bildung")
... getting corpus positions
... number of hits: 23
... checking that all p-attributes are available
... getting token id for p-attribute: word
... filtering by positivelist
... number of hits droped due to positivelist: 18
... generating contexts
... counting tokens
> y <- context(
+   p, query = "Integration", p_attribute = "word",
+   positivelist = c("[aA]rbeit.*", "Ausbildung"), regex = TRUE
+ )
... getting corpus positions
... number of hits: 23
... checking that all p-attributes are available
... getting token id for p-attribute: word
... filtering by positivelist
... number of hits droped due to positivelist: 21
... generating contexts
... counting tokens
> 
> 
> 
> cleanEx()
> nameEx("cooccurrences")
> ### * cooccurrences
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cooccurrences
> ### Title: Get cooccurrence statistics.
> ### Aliases: cooccurrences cooccurrences,character-method
> ###   cooccurrences,partition-method cooccurrences,context-method
> ###   cooccurrences,Corpus-method cooccurrences,partition_bundle-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> merkel <- partition("GERMAPARLMINI", interjection = "speech", speaker = ".*Merkel", regex = TRUE)
... get encoding: latin1
... get cpos and strucs
> merkel <- enrich(merkel, p_attribute = "word")
... getting counts for p-attribute(s): word
> cooc <- cooccurrences(merkel, query = "Deutschland")
> 
> 
> 
> cleanEx()
> nameEx("corpus-method")
> ### * corpus-method
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: corpus
> ### Title: Get corpus/corpora available or used.
> ### Aliases: corpus corpus,textstat-method corpus,kwic-method
> ###   corpus,bundle-method corpus,missing-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> corpus()
         corpus   size template
1 GERMAPARLMINI 222201     TRUE
2       REUTERS   4050     TRUE
> 
> p <- partition("REUTERS", places = "kuwait")
... get encoding: latin1
... get cpos and strucs
> corpus(p)
[1] "REUTERS"
> 
> pb <- partition_bundle("REUTERS", s_attribute = "id")
... getting matrix with regions for s-attribute:  id
... generating the partitions
> corpus(pb)
[1] "REUTERS"
> 
> 
> 
> cleanEx()
> nameEx("count-method")
> ### * count-method
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: count
> ### Title: Get counts.
> ### Aliases: count count-method count,partition-method
> ###   count,partition_bundle-method count,character-method
> ###   count,vector-method count,Corpus-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> debates <- partition("GERMAPARLMINI", date = ".*", regex=TRUE)
... get encoding: latin1
... get cpos and strucs
> count(debates, query = "Arbeit") # get frequencies for one token
... processing query Arbeit
    query count         freq
1: Arbeit   159 0.0007155683
> count(debates, c("Arbeit", "Freizeit", "Zukunft")) # get frequencies for multiple tokens
... processing query Arbeit
... processing query Freizeit
... processing query Zukunft
      query count         freq
1:   Arbeit   159 7.155683e-04
2: Freizeit     1 4.500430e-06
3:  Zukunft   142 6.390610e-04
>   
> count("GERMAPARLMINI", query = c("Migration", "Integration"), p_attribute = "word")
         query count         freq
1:   Migration     3 1.350129e-05
2: Integration    23 1.035099e-04
> 
> debates <- partition_bundle(
+   "GERMAPARLMINI", s_attribute = "date", values = NULL,
+   regex = TRUE, mc = FALSE, verbose = FALSE
+ )
> y <- count(debates, query = "Arbeit", p_attribute = "word")
... adding total number of hits (col 'TOTAL', verbose = verbose)
> y <- count(debates, query = c("Arbeit", "Migration", "Zukunft"), p_attribute = "word")
... adding total number of hits (col 'TOTAL', verbose = verbose)
>   
> count("GERMAPARLMINI", '"Integration.*"', breakdown = TRUE)
              query                       match count share
 1: "Integration.*"                 Integration    23 56.10
 2: "Integration.*"         Integrationspolitik     9 21.95
 3: "Integration.*"           Integrationskurse     2  4.88
 4: "Integration.*"        Integrationsangebote     1  2.44
 5: "Integration.*"    Integrationsbereitschaft     1  2.44
 6: "Integration.*"         Integrationserfolge     1  2.44
 7: "Integration.*"       Integrationskarrieren     1  2.44
 8: "Integration.*" Integrationspartnerschaften     1  2.44
 9: "Integration.*"            Integrationsplan     1  2.44
10: "Integration.*"      Integrationspolitik.Es     1  2.44
> 
> P <- partition("GERMAPARLMINI", date = "2009-11-11")
... get encoding: latin1
... get cpos and strucs
> count(P, '"Integration.*"', breakdown = TRUE)
             query                    match count share
1: "Integration.*"              Integration    15 50.00
2: "Integration.*"      Integrationspolitik     8 26.67
3: "Integration.*"        Integrationskurse     2  6.67
4: "Integration.*"     Integrationsangebote     1  3.33
5: "Integration.*" Integrationsbereitschaft     1  3.33
6: "Integration.*"      Integrationserfolge     1  3.33
7: "Integration.*"    Integrationskarrieren     1  3.33
8: "Integration.*"   Integrationspolitik.Es     1  3.33
> 
> 
> 
> cleanEx()
> nameEx("cqp")
> ### * cqp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cqp
> ### Title: Tools for CQP queries.
> ### Aliases: cqp is.cqp as.cqp
> 
> ### ** Examples
> 
> is.cqp("migration") # will return FALSE
[1] FALSE
> is.cqp('"migration"') # will return TRUE
[1] TRUE
> is.cqp('[pos = "ADJA"] "migration"') # will return TRUE
[1] TRUE
> 
> as.cqp("migration")
      migration 
"\"migration\"" 
> as.cqp(c("migration", "diversity"))
      migration       diversity 
"\"migration\"" "\"diversity\"" 
> as.cqp(c("migration", "diversity"), collapse = TRUE)
[1] "(\"migration\"|\"diversity\")"
> as.cqp("migration", normalise.case = TRUE)
         migration 
"\"migration\" %c" 
> 
> 
> 
> cleanEx()
> nameEx("decode")
> ### * decode
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: decode
> ### Title: Decode Structural Attribute or Entire Corpus.
> ### Aliases: decode decode,character-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> 
> # Scenario 1: Decode one or two s-attributes
> dt <- decode("GERMAPARLMINI", s_attribute = "date")
... decoding s-attribute:  date
> dt <- decode("GERMAPARLMINI", s_attribute = c("date", "speaker"))
... decoding s-attribute:  date
... decoding s-attribute:  speaker
> 
> # Scenario 2: Decode corpus entirely
> dt <- decode("GERMAPARLMINI")
... decoding p-attribute: word
... decoding p-attribute: pos
... decoding s-attribute: interjection
... decoding s-attribute: date
... decoding s-attribute: party
... decoding s-attribute: speaker
... assembling data.table
> 
> 
> 
> cleanEx()
> nameEx("dispersion-method")
> ### * dispersion-method
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dispersion
> ### Title: Dispersion of a query or multiple queries
> ### Aliases: dispersion dispersion,partition-method dispersion
> ###   dispersion,character-method dispersion,hits-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> test <- partition("GERMAPARLMINI", date = ".*", p_attribute = NULL, regex = TRUE)
... get encoding: latin1
... get cpos and strucs
> integration <- dispersion(
+   test, query = "Integration",
+   p_attribute = "word", s_attribute = "date"
+ )
> integration <- dispersion(test, "Integration", s_attribute = c("date", "party"))
> integration <- dispersion(test, '"Integration.*"', s_attribute = "date", cqp = TRUE)
> 
> 
> 
> cleanEx()
> nameEx("features")
> ### * features
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: features
> ### Title: Get features by comparison.
> ### Aliases: features features,partition-method features,count-method
> ###   features,partition_bundle-method features,ngrams-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> 
> kauder <- partition(
+   "GERMAPARLMINI",
+   speaker = "Volker Kauder", interjection = "speech",
+   p_attribute = "word"
+   )
... get encoding: latin1
... get cpos and strucs
... getting counts for p-attribute(s): word
> all <- partition("GERMAPARLMINI", interjection = "speech", p_attribute = "word")
... get encoding: latin1
... get cpos and strucs
... getting counts for p-attribute(s): word
> 
> terms_kauder <- features(x = kauder, y = all, included = TRUE)
> top100 <- subset(terms_kauder, rank_chisquare <= 100)
> head(top100)
               word word_id.x count_coi word_id.y count_ref    exp_coi
1:     Zusammenhalt      2538        12      2538        32 0.79902610
2:           Räumen      5545         5      5545         4 0.16343716
3:         Deswegen      4340        18      4340       105 2.23364113
4: Ballungsgebieten      5543         2      5543         0 0.03631937
5:        Höchstmaß      5422         2      5422         0 0.03631937
6:           langer      5517         2      5517         0 0.03631937
   chisquare rank_chisquare
1:  159.9600              1
2:  145.7816              2
3:  113.4208              3
4:  108.1352              4
5:  108.1352              5
6:  108.1352              6
> 
> # a different way is to compare count objects
> kauder_count <- as(kauder, "count")
> all_count <- as(all, "count")
> terms_kauder <- features(kauder_count, all_count, included = TRUE)
... combining frequency lists
... statistical test:  chisquare
> top100 <- subset(terms_kauder, rank_chisquare <= 100)
> head(top100)
               word word_id.x count_coi word_id.y count_ref    exp_coi
1:     Zusammenhalt      2538        12      2538        32 0.79902610
2:           Räumen      5545         5      5545         4 0.16343716
3:         Deswegen      4340        18      4340       105 2.23364113
4: Ballungsgebieten      5543         2      5543         0 0.03631937
5:        Höchstmaß      5422         2      5422         0 0.03631937
6:           langer      5517         2      5517         0 0.03631937
   chisquare rank_chisquare
1:  159.9600              1
2:  145.7816              2
3:  113.4208              3
4:  108.1352              4
5:  108.1352              5
6:  108.1352              6
> 
> speakers <- partition_bundle("GERMAPARLMINI", s_attribute = "speaker")
... getting matrix with regions for s-attribute:  speaker
... generating the partitions
> speakers <- enrich(speakers, p_attribute = "word")
> speaker_terms <- features(speakers[[1:5]], all, included = TRUE, progress = TRUE)
> dtm <- as.DocumentTermMatrix(speaker_terms, col = "chisquare")
... using the p_attribute-slot of the first object in the bundle as p_attribute: word
... generating (temporary) key column
... generating cumulated data.table
... getting unique keys
... generating integer keys
... cleaning up temporary key columns
> 
> 
> 
> cleanEx()
> nameEx("get_token_stream-method")
> ### * get_token_stream-method
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: get_token_stream
> ### Title: Get Token Stream Based on Corpus Positions.
> ### Aliases: get_token_stream get_token_stream,numeric-method
> ###   get_token_stream,matrix-method get_token_stream,character-method
> ###   get_token_stream,partition-method get_token_stream,regions-method
> 
> ### ** Examples
> 
> get_token_stream(0:9, corpus = "GERMAPARLMINI", p_attribute = "word")
 [1] "Guten"     "Morgen"    ","         "meine"     "sehr"      "verehrten"
 [7] "Damen"     "und"       "Herren"    "!"        
> get_token_stream(0:9, corpus = "GERMAPARLMINI", p_attribute = "word", collapse = " ")
[1] "Guten Morgen, meine sehr verehrten Damen und Herren!"
> fulltext <- get_token_stream("GERMAPARLMINI", p_attribute = "word")
> 
> 
> 
> cleanEx()
> nameEx("get_type")
> ### * get_type
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: get_type
> ### Title: Get corpus/partition type.
> ### Aliases: get_type get_type,character-method get_type,Corpus-method
> ###   get_type,partition-method get_type,partition_bundle-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> 
> get_type("GERMAPARLMINI")
[1] "plpr"
> 
> p <- partition("GERMAPARLMINI", date = "2009-10-28")
... get encoding: latin1
... get cpos and strucs
> get_type(p)
[1] "plpr"
> is(p)
[1] "plpr_partition" "partition"      "count"          "subcorpus"     
[5] "textstat"      
> 
> pb <- partition_bundle("GERMAPARLMINI", s_attribute = "date")
... getting matrix with regions for s-attribute:  date
... generating the partitions
> get_type(pb)
[1] "plpr"
> 
> gp <- Corpus$new("GERMAPARLMINI") 
> get_type(gp)
[1] "plpr"
> 
> get_type("REUTERS") # returns NULL - no specialized corpus
NULL
> 
> 
> 
> cleanEx()
> nameEx("highlight")
> ### * highlight
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: highlight
> ### Title: Highlight tokens in text output.
> ### Aliases: highlight highlight,character-method highlight,html-method
> ###   highlight,kwic-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> P <- partition("REUTERS", places = "argentina")
... get encoding: latin1
... get cpos and strucs
> H <- html(P)
> Y <- highlight(H, list(lightgreen = "higher"))
> if (interactive()) htmltools::html_print(Y)
> 
> # highlight matches for a CQP query
> H2 <- highlight(
+   H,
+   highlight = list(yellow = cpos(hits(P, query = '"prod.*"', cqp = TRUE)))
+ )
> 
> # the method can be used in pipe
> if (require("magrittr")){
+   P %>% html() %>% highlight(list(lightgreen = "1986")) -> H
+   P %>% html() %>% highlight(list(lightgreen = c("1986", "higher"))) -> H
+   P %>% html() %>% highlight(list(lightgreen = 4020:4023)) -> H
+ }
Loading required package: magrittr
> 
> # use highlight for kwic output
> K <- kwic("REUTERS", query = "barrel")
> K2 <- highlight(K, highlight = list(yellow = c("oil", "price")))
> if (interactive()) K2
> 
> # use character vector for output, not list
> K2 <- highlight(
+   K,
+   highlight = c(
+     green = "pric.",
+     red = "reduction",
+     red = "decrease",
+     orange = "dropped"),
+     regex = TRUE
+ )
> if (interactive()) K2
> 
> 
> 
> cleanEx()

detaching ‘package:magrittr’

> nameEx("html-method")
> ### * html-method
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: html
> ### Title: Generate html from object.
> ### Aliases: html show,html-method html,character-method
> ###   html,partition-method html,partition_bundle-method html,kwic-method
> ###   print.html
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> P <- partition("REUTERS", places = "argentina")
... get encoding: latin1
... get cpos and strucs
> H <- html(P)
> if (interactive()) H # show full text in viewer pane
> 
> # html-method can be used in a pipe
> if (require("magrittr")){
+   H <- partition("REUTERS", places = "argentina") %>% html()
+   # use html-method to get from concordance to full text
+   K <- kwic("REUTERS", query = "barrels")
+   H <- html(K, i = 1, s_attribute = "id")
+   H <- html(K, i = 2, s_attribute = "id")
+   for (i in 1:length(K)) {
+     H <- html(K, i = i, s_attribute = "id")
+     if (interactive()){
+       show(H)
+       userinput <- readline("press 'q' to quit or any other key to continue")
+       if (userinput == "q") break
+     }
+   }
+ }
Loading required package: magrittr
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
... get encoding: latin1
... get cpos and strucs
> 
> 
> 
> 
> cleanEx()

detaching ‘package:magrittr’

> nameEx("kwic-class")
> ### * kwic-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: kwic-class
> ### Title: kwic (S4 class)
> ### Aliases: kwic-class [,kwic,ANY,ANY,ANY-method [,kwic-method
> ###   show,kwic-method knit_print,kwic-method as.character,kwic-method
> ###   [,kwic,ANY,ANY,ANY-method subset,kwic-method
> ###   as.data.frame,kwic-method length,kwic-method sample,kwic-method
> ###   enrich,kwic-method view,kwic-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> K <- kwic("GERMAPARLMINI", "Integration")
> length(K)
[1] 23
> K[1]
> K[1:5]
> oil <- kwic("REUTERS", query = "oil")
> as.character(oil)
 [1] "cut its contract prices for crude <i>oil</i> by 1.50 dlrs a barrel The"                             
 [2] "made in the light of falling <i>oil</i> product prices and a weak crude"                            
 [3] "product prices and a weak crude <i>oil</i> market a company spokeswoman said Diamond"               
 [4] "latest in a line of U.S <i>oil</i> companies that have cut its contract"                            
 [5] "the last two days citing weak <i>oil</i> markets Reuter OPEC may be forced"                         
 [6] "to halt the current slide in <i>oil</i> prices oil industry analysts said The"                      
 [7] "the current slide in oil prices <i>oil</i> industry analysts said The movement to"                  
 [8] "analysts said The movement to higher <i>oil</i> prices was never to be as"                          
 [9] "Energy Research Associates CERA Analysts and <i>oil</i> industry sources said the problem OPEC"     
[10] "the problem OPEC faces is excess <i>oil</i> supply in world oil markets OPEC's"                     
[11] "is excess oil supply in world <i>oil</i> markets OPEC's problem is not a"                           
[12] "in that way said Paul Mlotok <i>oil</i> analyst with Salomon Brothers Inc He"                       
[13] "wishes to regain the initiative in <i>oil</i> prices But some other analysts were"                  
[14] "manager for one of the major <i>oil</i> companies who spoke on condition that"                      
[15] "the winter demand to sell their <i>oil</i> but in late March and April"                             
[16] "said that the demand for OPEC <i>oil</i> has been rising through the first"                         
[17] "its production Demand for their OPEC <i>oil</i> is clearly above 15.8 mln bpd"                      
[18] "price it will pay for crude <i>oil</i> 64 Canadian cts a barrel effective"                          
[19] "Texaco Canada last changed its crude <i>oil</i> postings on Feb 19 Reuter Marathon"                 
[20] "pay for all grades of crude <i>oil</i> one dlr a barrel effective today"                            
[21] "an emergency OPEC meeting to review <i>oil</i> policies after recent weakness in world"             
[22] "policies after recent weakness in world <i>oil</i> prices Sheikh Ali al Khalifa al"                 
[23] "organisation Traders and analysts in international <i>oil</i> markets estimate OPEC is producing up"
[24] "delivered a challenge to any international <i>oil</i> company that declared Kuwait sold below"      
[25] "Kuwait had guaranteed markets for its <i>oil</i> because of its local and international"            
[26] "pricing committee Referring to pressure by <i>oil</i> companies on OPEC members in apparent"        
[27] "a new report To counter falling <i>oil</i> revenues the government has launched a"                  
[28] "months to boost exports outside the <i>oil</i> sector and attract new investment Indonesia"         
[29] "last year s fall in world <i>oil</i> prices which forced it to devalue"                             
[30] "petroleum industry Growth in the non <i>oil</i> sector is low because of weak"                      
[31] "in halting the current decline in <i>oil</i> prices Oil industry sources said yesterday"            
[32] "Arab producers had had difficulty selling <i>oil</i> at official OPEC prices but Kuwait"            
[33] "3.7500 03 yesterday REUTER The Gulf <i>oil</i> state of Qatar recovering slightly from"             
[34] "from last year's decline in world <i>oil</i> prices announced its first budget since"               
[35] "87 budget due to uncertainty surrounding <i>oil</i> revenues Sheikh Abdul Aziz said that"           
[36] "There was also no projection for <i>oil</i> revenue Qatar an OPEC member has"                       
[37] "Our expectations of positive signs regarding <i>oil</i> price trends foremost among them OPEC's"    
[38] "December's OPEC accord to boost world <i>oil</i> prices and stabilise the market the"               
[39] "the recent fall in free market <i>oil</i> prices Nazer said Saudi Arabia is"                        
[40] "and it will never sell its <i>oil</i> at prices below the pronounced prices"                        
[41] "followed a year of turmoil on <i>oil</i> markets which saw prices slump briefly"                    
[42] "accord was shown clearly in the <i>oil</i> market He said contacts among members"                   
[43] "prices Traders and analysts in international <i>oil</i> markets estimate OPEC is producing up"      
[44] "was over producing REUTER Saudi crude <i>oil</i> output last month fell to an"                      
[45] "3.8 mln bpd in January Gulf <i>oil</i> sources said They said exports from"                         
[46] "last December to back new official <i>oil</i> prices averaging 18 dlrs a barrel"                    
[47] "dlr below Opec levels Saudi Arabian <i>oil</i> minister Hisham Nazer yesterday reiterated the"      
[48] "Jubail export refineries They put crude <i>oil</i> exports through Yanbu at 100,000 bpd"            
[49] "around 200,000 bpd each REUTER Deputy <i>oil</i> ministers from six Gulf Arab states"               
[50] "today to discuss coordination of crude <i>oil</i> marketing the official Emirates news agency"      
[51] "Doha by Gulf Cooperation Council GCC <i>oil</i> ministers to help each other market"                
[52] "help each other market their crude <i>oil</i> Four of the GCC states Saudi"                         
[53] "December's OPEC accord to boost world <i>oil</i> prices and stabilize the market the"               
[54] "the recent fall in free market <i>oil</i> prices Nazer said Saudi Arabia is"                        
[55] "and it will never sell its <i>oil</i> at prices below the pronounced prices"                        
[56] "OPEC agreed to cut its total <i>oil</i> output ceiling by 7.25 pct and"                             
[57] "18 dollars a barrel Reuter Kuwait's <i>oil</i> minister said in a newspaper interview"              
[58] "after the recent weakness in world <i>oil</i> prices Sheikh Ali al Khalifa al"                      
[59] "barrels of crude daily bpd Crude <i>oil</i> prices fell sharply last week as"                       
[60] "fell sharply last week as international <i>oil</i> traders and analysts estimated the 13"           
[61] "Philadelphia was closed when a Cypriot <i>oil</i> tanker Seapride II ran aground after"             
[62] "said He said there was no <i>oil</i> spill but the ship is lodged"                                  
[63] "on the high tide After delivering <i>oil</i> to a refinery in Paulsboro New"                        
[64] "present and future impact of low <i>oil</i> prices on the domestic oil industry"                    
[65] "low oil prices on the domestic <i>oil</i> industry U.S policy now is to"                            
[66] "also called for new research for <i>oil</i> exploration and development techniques It predicted"    
[67] "instead that such moves as increasing <i>oil</i> reserves and more exploration and development"     
[68] "present and future impact of low <i>oil</i> prices on the domestic oil industry"                    
[69] "low oil prices on the domestic <i>oil</i> industry U.S policy now is to"                            
[70] "also called for new research for <i>oil</i> exploration and development techniques It predicted"    
[71] "the full economic benefits of cheap <i>oil</i> But the group did not strongly"                      
[72] "instead that such moves as increasing <i>oil</i> reserves and more exploration and development"     
[73] "lowered its posted prices for crude <i>oil</i> one to 1.50 dlrs a barrel"                           
[74] "for West Coast grades of crude <i>oil</i> the company said Reuter The New"                          
[75] "On April one NYMEX will allow <i>oil</i> traders that do not hold a"                                
[76] "spokeswoman This will change the way <i>oil</i> is transacted in the real world"                    
[77] "will serve the industry because the <i>oil</i> market does not close when NYMEX"                    
[78] "a CFTC spokeswoman Reuter Argentine crude <i>oil</i> production was down 10.8 pct in"               
> 
> 
> 
> cleanEx()
> nameEx("kwic")
> ### * kwic
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: kwic
> ### Title: KWIC/concordance output.
> ### Aliases: kwic kwic,context-method kwic,partition-method
> ###   kwic,character-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> kwic("GERMAPARLMINI", "Integration")
> kwic(
+   "GERMAPARLMINI",
+   "Integration", left = 20, right = 20,
+   s_attributes = c("date", "speaker", "party")
+ )
> kwic(
+   "GERMAPARLMINI",
+   '"Integration" [] "(Menschen|Migrant.*|Personen)"', cqp = TRUE,
+   left = 20, right = 20,
+   s_attributes = c("date", "speaker", "party")
+ )
> 
> kwic(
+   "GERMAPARLMINI",
+   '"Sehr" "geehrte"', cqp = TRUE,
+   boundary = "date"
+ )
... checking that context positions to not transgress regions
... checking that all s-attributes are available
... get struc for s-attribute: date
... checking boundaries of regions
  |                                                                              |                                                                      |   0%  |                                                                              |====                                                                  |   5%  |                                                                              |=======                                                               |  10%  |                                                                              |==========                                                            |  15%  |                                                                              |==============                                                        |  20%  |                                                                              |==================                                                    |  25%  |                                                                              |=====================                                                 |  30%  |                                                                              |========================                                              |  35%  |                                                                              |============================                                          |  40%  |                                                                              |================================                                      |  45%  |                                                                              |===================================                                   |  50%  |                                                                              |======================================                                |  55%  |                                                                              |==========================================                            |  60%  |                                                                              |==============================================                        |  65%  |                                                                              |=================================================                     |  70%  |                                                                              |====================================================                  |  75%  |                                                                              |========================================================              |  80%  |                                                                              |============================================================          |  85%  |                                                                              |===============================================================       |  90%  |                                                                              |==================================================================    |  95%  |                                                                              |======================================================================| 100%
> 
> P <- partition("GERMAPARLMINI", date = "2009-11-10")
... get encoding: latin1
... get cpos and strucs
> kwic(P, query = "Integration")
... getting corpus positions
... number of hits: 7
... checking that all p-attributes are available
... getting token id for p-attribute: word
... generating contexts
> kwic(P, query = '"Sehr" "geehrte"', cqp = TRUE, boundary = "date")
... getting corpus positions
... number of hits: 6
... checking that all p-attributes are available
... getting token id for p-attribute: word
... generating contexts
... checking that context positions to not transgress regions
... checking that all s-attributes are available
... get struc for s-attribute: date
... checking boundaries of regions
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |============================                                          |  40%  |                                                                              |==========================================                            |  60%  |                                                                              |========================================================              |  80%  |                                                                              |======================================================================| 100%
> 
> 
> 
> cleanEx()
> nameEx("ngrams")
> ### * ngrams
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ngrams
> ### Title: Get N-Grams
> ### Aliases: ngrams ngrams,partition-method ngrams,partition_bundle-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> P <- partition("GERMAPARLMINI", date = "2009-10-27")
... get encoding: latin1
... get cpos and strucs
> ngramObject <- ngrams(P, n = 2, p_attribute = "word", char = NULL)
> 
> # a more complex scenario: get most frequent ADJA/NN-combinations
> ngramObject <- ngrams(P, n = 2, p_attribute = c("word", "pos"), char = NULL)
> ngramObject2 <- subset(
+  ngramObject,
+  ngramObject[["1_pos"]] == "ADJA"  & ngramObject[["2_pos"]] == "NN"
+  )
> ngramObject2@stat[, "1_pos" := NULL, with = FALSE][, "2_pos" := NULL, with = FALSE]
Warning in `[.data.table`(ngramObject2@stat, , `:=`("1_pos", NULL), with = FALSE) :
  with=FALSE ignored, it isn't needed when using :=. See ?':=' for examples.
Warning in `[.data.table`(ngramObject2@stat[, `:=`("1_pos", NULL), with = FALSE],  :
  with=FALSE ignored, it isn't needed when using :=. See ?':=' for examples.
> ngramObject3 <- sort(ngramObject2, by = "count")
> head(ngramObject3)
      1_word      2_word count
1:    ganzen       Hause    26
2:     Liebe Kolleginnen    10
3: Deutschen Bundestages     8
4: verehrten       Damen     7
5: Deutschen  Bundestags     3
6:  Deutsche   Bundestag     3
> 
> 
> 
> cleanEx()
> nameEx("p_attributes")
> ### * p_attributes
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: p_attributes
> ### Title: Get p-attributes.
> ### Aliases: p_attributes p_attributes,character-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> p_attributes("GERMAPARLMINI")
[1] "word" "pos" 
> 
> 
> 
> cleanEx()
> nameEx("partition")
> ### * partition
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: partition
> ### Title: Initialize a partition.
> ### Aliases: partition partition,character-method
> ###   partition,environment-method partition,partition-method
> ###   partition,Corpus-method partition,context-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> spd <- partition("GERMAPARLMINI", party = "SPD", interjection = "speech")
... get encoding: latin1
... get cpos and strucs
> kauder <- partition("GERMAPARLMINI", speaker = "Volker Kauder", p_attribute = "word")
... get encoding: latin1
... get cpos and strucs
... getting counts for p-attribute(s): word
> merkel <- partition("GERMAPARLMINI", speaker = ".*Merkel", p_attribute = "word", regex = TRUE)
... get encoding: latin1
... get cpos and strucs
... getting counts for p-attribute(s): word
> s_attributes(merkel, "date")
[1] "2009-10-28" "2009-11-10"
> s_attributes(merkel, "speaker")
[1] "Angela Dorothea Merkel"
> merkel <- partition(
+   "GERMAPARLMINI", speaker = "Angela Dorothea Merkel",
+   date = "2009-11-10", interjection = "speech", p_attribute = "word"
+   )
... get encoding: latin1
... get cpos and strucs
... getting counts for p-attribute(s): word
> merkel <- subset(merkel, !word %in% punctuation)
> merkel <- subset(merkel, !word %in% tm::stopwords("de"))
>    
> # a certain defined time segment
> days <- seq(
+   from = as.Date("2009-10-28"),
+   to = as.Date("2009-11-11"),
+   by = "1 day"
+ )
> period <- partition("GERMAPARLMINI", date = days)
... get encoding: latin1
... get cpos and strucs
> 
> 
> 
> cleanEx()
> nameEx("partition_bundle-method")
> ### * partition_bundle-method
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: partition_bundle
> ### Title: Generate bundle of partitions.
> ### Aliases: partition_bundle partition_bundle,partition-method
> ###   partition_bundle,character-method partition_bundle,context-method
> ###   partition_bundle,partition_bundle-method
> 
> ### ** Examples
> 
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> bt2009 <- partition("GERMAPARLMINI", date = "2009-.*", regex = TRUE)
... get encoding: latin1
... get cpos and strucs
> pb <- partition_bundle(bt2009, s_attribute = "date", progress = TRUE, p_attribute = "word")
... getting values for s-attribute  date
... number of partitions to be generated:  5
> dtm <- as.DocumentTermMatrix(pb, col = "count")
... using the p_attribute-slot of the first object in the bundle as p_attribute: word
... generating (temporary) key column
... generating cumulated data.table
... getting unique keys
... generating integer keys
... cleaning up temporary key columns
> summary(pb)
        name   size p_attribute unique
1 2009-10-27   9341        word   2239
2 2009-10-28   2793        word    652
3 2009-11-10  68316        word   8432
4 2009-11-11 117614        word  12080
5 2009-11-12  24137        word   4400
> pb <- partition_bundle("GERMAPARLMINI", s_attribute = "date")
... getting matrix with regions for s-attribute:  date
... generating the partitions
> # split up objects in partition_bundle by using partition_bundle-method
> use("polmineR")
... activating corpus: germaparlmini
... activating corpus: reuters
> pb <- partition_bundle("GERMAPARLMINI", s_attribute = "date")
... getting matrix with regions for s-attribute:  date
... generating the partitions
> pb2 <- partition_bundle(pb, s_attribute = "speaker", progress = FALSE)
> 
> summary(pb2)
                                             name size
1                    2009-10-27_Heinz Riesenhuber 4766
2                        2009-10-27_Volker Kauder   38
3                      2009-10-27_Norbert Lammert 4441
4                    2009-10-27_Gerda Hasselfeldt   23
5                     2009-10-27_Wolfgang Thierse   14
6                   2009-10-27_Hermann Otto Solms   17
7                            2009-10-27_Petra Pau   25
8                2009-10-27_Katrin Göring-Eckardt   17
9                      2009-10-28_Norbert Lammert 2519
10              2009-10-28_Angela Dorothea Merkel  127
11                   2009-10-28_Guido Westerwelle   10
12  2009-10-28_Sabine Leutheusser-Schnarrenberger   10
13                   2009-10-28_Wolfgang Schäuble   10
14                     2009-10-28_Rainer Brüderle   10
15                    2009-10-28_Franz Josef Jung   10
16                         2009-10-28_Ilse Aigner   10
17         2009-10-28_Karl-Theodor  zu Guttenberg   10
18               2009-10-28_Ursula  von der Leyen   10
19                      2009-10-28_Philipp Rösler   10
20                      2009-10-28_Peter Ramsauer   10
21                     2009-10-28_Annette Schavan   10
22                         2009-10-28_Dirk Niebel   10
23                      2009-10-28_Ronald Pofalla   27
24                     2009-11-10_Norbert Lammert  365
25              2009-11-10_Angela Dorothea Merkel 8988
26             2009-11-10_Frank-Walter Steinmeier 4476
27                    2009-11-10_Birgit Homburger 4311
28                    2009-11-10_Wolfgang Thierse 4713
29                    2009-11-10_Oskar Lafontaine 3337
30                      2009-11-10_Jürgen Trittin 2477
31                       2009-11-10_Volker Kauder 3956
32                         2009-11-10_Joachim Poß 1772
33                2009-11-10_Hans-Peter Friedrich  759
34                     2009-11-10_Agnes Krumwiede  779
35                   2009-11-10_Gerda Hasselfeldt  350
36                        2009-11-10_Arnold Vaatz 1603
37                   2009-11-10_Guido Westerwelle 1566
38                        2009-11-10_Gernot Erler 1210
39                2009-11-10_Andreas Schockenhoff 2825
40                       2009-11-10_Jan  van Aken 1364
41                    2009-11-10_Frithjof Schmidt 1264
42                         2009-11-10_Dirk Niebel 1409
43                        2009-11-10_Sascha Raabe  199
44              2009-11-10_Angelica Schwall-Düren 1230
45         2009-11-10_Karl-Theodor  zu Guttenberg 3016
46                    2009-11-10_Wolfgang Gehrcke 1291
47                      2009-11-10_Omid Nouripour  812
48                           2009-11-10_Petra Pau   81
49                         2009-11-10_Ilse Aigner 1321
50                      2009-11-10_Waltraud Wolff 1490
51               2009-11-10_Hans-Michael Goldmann 1239
52               2009-11-10_Katrin Göring-Eckardt  519
53                    2009-11-10_Kirsten Tackmann 1009
54                       2009-11-10_Ulrike Höfken 1374
55                        2009-11-10_Peter Bleser 1778
56               2009-11-10_Elvira Drobinski-Weiß 1062
57              2009-11-10_Christel Happach-Kasan 1336
58                           2009-11-10_Caren Lay  702
59                     2009-11-10_Johannes Röring 1081
60                  2009-11-10_Wilhelm Priesmeier 1252
61                     2009-11-11_Norbert Lammert 1724
62                     2009-11-11_Rainer Brüderle 1367
63                       2009-11-11_Hubertus Heil 6117
64         2009-11-11_Michael Franz Wilhelm Fuchs 2361
65                   2009-11-11_Sahra Wagenknecht 1063
66                     2009-11-11_Kerstin Andreae 2097
67                         2009-11-11_Ulla Lötzer  707
68                    2009-11-11_Joachim Pfeiffer 2051
69                       2009-11-11_Georg Nüßlein 2277
70                       2009-11-11_Ulrich Kelber 1243
71                     2009-11-11_Norbert Röttgen 2670
72                    2009-11-11_Wolfgang Thierse  272
73                       2009-11-11_Michael Kauch 1274
74                2009-11-11_Eva Bulling-Schröter  854
75                         2009-11-11_Bärbel Höhn 1671
76                    2009-11-11_Marie-Luise Dött 1195
77                         2009-11-11_Marco Bülow 1355
78                    2009-11-11_Horst Meierhofer 1366
79                    2009-11-11_Dorothée Menzner  772
80                        2009-11-11_Josef Göppel  746
81                       2009-11-11_Frank Schwabe 1279
82                      2009-11-11_Peter Ramsauer 2168
83                     2009-11-11_Florian Pronold 1327
84                      2009-11-11_Patrick Döring 2144
85                       2009-11-11_Heidrun Bluhm 1045
86                    2009-11-11_Winfried Hermann 1601
87                   2009-11-11_Gerda Hasselfeldt  636
88                        2009-11-11_Dirk Fischer 1301
89                  2009-11-11_Uwe Karl Beckmeyer 1170
90                          2009-11-11_Peter Götz  882
91                       2009-11-11_Sabine Leidig 1048
92                        2009-11-11_Sören Bartol 1158
93                    2009-11-11_Franz Josef Jung 1653
94              2009-11-11_Heinrich Leonhard Kolb 2016
95                         2009-11-11_Klaus Ernst 1236
96                    2009-11-11_Brigitte Pothmer 1795
97                        2009-11-11_Markus Kurth   92
98                   2009-11-11_Karl Schiewerling 2018
99                         2009-11-11_Elke Ferner 2053
100                     2009-11-11_Johannes Vogel 1072
101                      2009-11-11_Katja Kipping  821
102                 2009-11-11_Hermann Otto Solms 4001
103                    2009-11-11_Max Straubinger 1578
104                       2009-11-11_Anton Schaaf  332
105                        2009-11-11_Volker Beck  121
106                        2009-11-11_Olaf Scholz 3741
107                       2009-11-11_Gisela Piltz 1775
108                   2009-11-11_Wolfgang Wieland 1606
109                 2009-11-11_Dieter Wiefelspütz 1268
110                     2009-11-11_Hartfrid Wolff 1432
111                     2009-11-11_Hans-Peter Uhl 1388
112                        2009-11-11_Ulla Jelpke  589
113                   2009-11-11_Reinhard Grindel 1407
114                     2009-11-11_Dagmar Ziegler 4073
115 2009-11-11_Sabine Leutheusser-Schnarrenberger 1338
116              2009-11-11_Katrin Göring-Eckardt 4281
117                      2009-11-11_Günter Krings   40
118                        2009-11-11_Raju Sharma  536
119                       2009-11-11_Jerzy Montag 1431
120                2009-11-11_Christine Lambrecht 1901
121              2009-11-11_Michael Grosse-Brömer 1530
122                     2009-11-11_Jens Petermann  641
123                       2009-11-11_Daniela Raab 1506
124                   2009-11-11_Halina Wawzyniak  524
125                    2009-11-11_Annette Schavan 2048
126                  2009-11-11_Patrick Meinhardt 1398
127                        2009-11-11_Petra Sitte 1810
128                          2009-11-11_Petra Pau  229
129                       2009-11-11_Krista Sager 1451
130                 2009-11-11_Michael Kretschmer 1489
131              2009-11-11_Ernst Dieter Rossmann 1721
132                     2009-11-11_Martin Neumann  771
133                   2009-11-11_Albert Rupprecht 1055
134              2009-11-11_Ursula  von der Leyen 1846
135                        2009-11-11_Miriam Gruß 1540
136                    2009-11-11_Jörn Wunderlich 1855
137                       2009-11-11_Ekin Deligöz 1665
138                  2009-11-12_Gerda Hasselfeldt 1923
139                     2009-11-12_Philipp Rösler 1636
140                        2009-11-12_Elke Ferner 2965
141                    2009-11-12_Wolfgang Zöller 1633
142                     2009-11-12_Birgitt Bender  979
143                       2009-11-12_Ulrike Flach  876
144                    2009-11-12_Norbert Lammert  326
145                     2009-11-12_Carola Reimann 1299
146                    2009-11-12_Rolf Koschorrek 1671
147             2009-11-12_Elisabeth Scharfenberg  845
148                         2009-11-12_Jens Spahn 1434
149                  2009-11-12_Barbara Hendricks   22
150                  2009-11-12_Wolfgang Schäuble 2921
151                        2009-11-12_Joachim Poß 1573
152                 2009-11-12_Hermann Otto Solms   53
153                 2009-11-12_Carl-Ludwig Thiele 1572
154                     2009-11-12_Gesine Lötzsch 1313
155                    2009-11-12_Alexander Bonde 1096
> 
> 
> 
> cleanEx()
> nameEx("polmineR")
> ### * polmineR
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: polmineR
> ### Title: polmineR-package
> ### Aliases: polmineR polmineR-package
> ### Keywords: package
> 
> ### ** Examples
> 
> use("polmineR") # activate demo corpora included in the package
... activating corpus: germaparlmini
... activating corpus: reuters
> 
> # Core methods applied to corpus
> 
> count("REUTERS", query = "oil")
   query count       freq
1:   oil    78 0.01925926
> count("REUTERS", query = c("oil", "barrel"))
    query count        freq
1:    oil    78 0.019259259
2: barrel    15 0.003703704
> count("REUTERS", query = '"Saudi" "Arab.*"', breakdown = TRUE, cqp = TRUE)
              query          match count share
1: "Saudi" "Arab.*"   Saudi Arabia     6    50
2: "Saudi" "Arab.*" Saudi Arabia's     3    25
3: "Saudi" "Arab.*"  Saudi Arabian     3    25
> dispersion("REUTERS", query = "oil", s_attribute = "id")
     id count
 1: 127     5
 2: 144    12
 3: 191     2
 4: 194     1
 5: 236     6
 6: 237     4
 7: 242     2
 8: 246     5
 9: 248     6
10: 273     5
11: 349     4
12: 352     4
13: 353     4
14: 368     3
15: 489     4
16: 502     5
17: 543     2
18: 704     3
19: 708     1
> kwic("REUTERS", query = "oil")
> cooccurrences("REUTERS", query = "oil")
Warning in get("View", envir = .GlobalEnv)(.Object@stat) :
  unable to open display
Error in .External2(C_dataviewer, x, title) : unable to start data viewer
Calls: <Anonymous> ... <Anonymous> -> view -> view -> .local -> <Anonymous>
Execution halted
